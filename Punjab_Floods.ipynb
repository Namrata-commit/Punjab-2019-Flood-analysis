{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python API package is called ee. It must be imported and initialized for each new Python session and script.\n",
    "Authenticate to the Earth Engine servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "\n",
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:    \n",
    "    ee.Initialize()\n",
    "    print('Google Earth Engine has initialized successfully!')\n",
    "except ee.EEException as e:\n",
    "    print('Google Earth Engine has failed to initialize!')\n",
    "except:\n",
    "    print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipyleaflet import *\n",
    "from ipywidgets import jslink\n",
    "from geemap.utils import *\n",
    "from IPython.display import display\n",
    "import geemap\n",
    "\n",
    "Map = geemap.Map(height='800px')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the shape file of the flooded districts in Punjab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "floodedDistricts = ee.FeatureCollection('users/namratas/FloodedPunjabdistricts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map.setOptions('TERRAIN')\n",
    "Map.centerObject(floodedDistricts, 8)\n",
    "\n",
    "# Create an empty image into which to paint the features, cast to byte.\n",
    "empty = ee.Image().byte()\n",
    "\n",
    "# Paint both the fill and the edges.\n",
    "filledOutlines = empty.paint(floodedDistricts, 'BIOME_NUM').paint(floodedDistricts, 0, 2)\n",
    "Map.addLayer(filledOutlines, {\"palette\": 'BEBEBE', max: 14}, 'ROI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the time periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "beforeStart = '2019-03-13'\n",
    "beforeEnd = '2019-06-13'\n",
    "\n",
    "afterStart = '2019-08-21'\n",
    "afterEnd = '2019-09-16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = ee.ImageCollection(\"COPERNICUS/S1_GRD\")\n",
    "\n",
    "s1Collection = s1.filter(ee.Filter.eq('instrumentMode', 'IW'))\\\n",
    "                      .filter(ee.Filter.eq('transmitterReceiverPolarisation', ['VV','VH'])) \\\n",
    "                      .filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING'))\\\n",
    "                      .filter(ee.Filter.eq('resolution_meters',10)) \\\n",
    "                      .filterBounds(floodedDistricts) \\\n",
    "                      .select('V.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_collection = s1Collection.select('VH').filterDate(beforeStart, beforeEnd)\n",
    "after_collection = s1Collection.select('VH').filterDate(afterStart, afterEnd)\n",
    "\n",
    "before = before_collection.mosaic().clip(floodedDistricts)\n",
    "after = after_collection.mosaic().clip(floodedDistricts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refined Lee Speckle Filter for flood assessment, as coded in the SNAP 3.0 S1TBX\n",
    "https://github.com/senbox-org/s1tbx/blob/master/s1tbx-op-sar-processing/src/main/java/org/esa/s1tbx/sar/gpf/filtering/SpeckleFilters/RefinedLee.java and adapted by Guido Lemoine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert from dB\n",
    "def toNatural(img):\n",
    "    return ee.Image(10.0).pow(img.select(0).divide(10.0))\n",
    "\n",
    "# Function to convert to dB\n",
    "def toDB(img):\n",
    "    return ee.Image(img).log10().multiply(10.0)\n",
    "\n",
    "def RefinedLee(img):\n",
    "    # img must be in natural units, i.e. not in dB!\n",
    "    # Set up 3x3 kernels \n",
    "    weights3 = ee.List.repeat(ee.List.repeat(1,3),3)\n",
    "    kernel3 = ee.Kernel.fixed(3,3, weights3, 1, 1, False)\n",
    "    \n",
    "    mean3 = img.reduceNeighborhood(ee.Reducer.mean(), kernel3)\n",
    "    variance3 = img.reduceNeighborhood(ee.Reducer.variance(), kernel3)\n",
    "\n",
    "    # Use a sample of the 3x3 windows inside a 7x7 windows to determine gradients and directions\n",
    "    sample_weights = ee.List([[0,0,0,0,0,0,0], [0,1,0,1,0,1,0],\\\n",
    "                             [0,0,0,0,0,0,0], [0,1,0,1,0,1,0], \\\n",
    "                             [0,0,0,0,0,0,0], [0,1,0,1,0,1,0],[0,0,0,0,0,0,0]])\n",
    "\n",
    "    sample_kernel = ee.Kernel.fixed(7,7, sample_weights, 3,3, False)\n",
    "\n",
    "    # Calculate mean and variance for the sampled windows and store as 9 bands\n",
    "    sample_mean = mean3.neighborhoodToBands(sample_kernel)\n",
    "    sample_var = variance3.neighborhoodToBands(sample_kernel)\n",
    "\n",
    "    # Determine the 4 gradients for the sampled windows\n",
    "    gradients = sample_mean.select(1).subtract(sample_mean.select(7)).abs()\n",
    "    gradients = gradients.addBands(sample_mean.select(6).subtract(sample_mean.select(2)).abs())\n",
    "    gradients = gradients.addBands(sample_mean.select(3).subtract(sample_mean.select(5)).abs())\n",
    "    gradients = gradients.addBands(sample_mean.select(0).subtract(sample_mean.select(8)).abs())\n",
    "\n",
    "    # And find the maximum gradient amongst gradient bands\n",
    "    max_gradient = gradients.reduce(ee.Reducer.max())\n",
    "\n",
    "    # Create a mask for band pixels that are the maximum gradient\n",
    "    gradmask = gradients.eq(max_gradient)\n",
    "\n",
    "    # duplicate gradmask bands: each gradient represents 2 directions\n",
    "    gradmask = gradmask.addBands(gradmask)\n",
    "\n",
    "    # Determine the 8 directions\n",
    "    directions = sample_mean.select(1) \\\n",
    "                            .subtract(sample_mean.select(4)) \\\n",
    "                            .gt(sample_mean.select(4).subtract(sample_mean.select(7))) \\\n",
    "                            .multiply(1)\n",
    "    directions = directions.addBands(sample_mean.select(6).subtract(sample_mean.select(4)) \\\n",
    "                           .gt(sample_mean.select(4).subtract(sample_mean.select(2))) \\\n",
    "                           .multiply(2))\n",
    "    directions = directions.addBands(sample_mean.select(3).subtract(sample_mean.select(4)) \\\n",
    "                           .gt(sample_mean.select(4).subtract(sample_mean.select(5))) \\\n",
    "                           .multiply(3))\n",
    "    directions = directions.addBands(sample_mean.select(0).subtract(sample_mean.select(4)) \\\n",
    "                           .gt(sample_mean.select(4).subtract(sample_mean.select(8))) \\\n",
    "                           .multiply(4))\n",
    "    # The next 4 are the not() of the previous 4\n",
    "    directions = directions.addBands(directions.select(0).Not().multiply(5))\n",
    "    directions = directions.addBands(directions.select(1).Not().multiply(6))\n",
    "    directions = directions.addBands(directions.select(2).Not().multiply(7))\n",
    "    directions = directions.addBands(directions.select(3).Not().multiply(8))\n",
    "\n",
    "    # Mask all values that are not 1-8\n",
    "    directions = directions.updateMask(gradmask)\n",
    "\n",
    "    # \"collapse\" the stack into a singe band image (due to masking, each pixel has just \n",
    "    # one value (1-8) in it's directional band, and is otherwise masked)\n",
    "    directions = directions.reduce(ee.Reducer.sum()) \n",
    "\n",
    "    pal = ['ffffff','ff0000','ffff00', '00ff00', '00ffff', '0000ff', 'ff00ff', '000000']\n",
    "    # Map.addLayer(directions.reduce(ee.Reducer.sum()), {min:1, max:8, palette: pal}, 'Directions', false)\n",
    "\n",
    "    sample_stats = sample_var.divide(sample_mean.multiply(sample_mean))\n",
    "\n",
    "    # Calculate localNoiseVariance\n",
    "    sigmaV = sample_stats.toArray().arraySort().arraySlice(0,0,5).arrayReduce(ee.Reducer.mean(), [0])\n",
    "\n",
    "    # Set up the 7*7 kernels for directional statistics\n",
    "    rect_weights = ee.List.repeat(ee.List.repeat(0,7),3).cat(ee.List.repeat(ee.List.repeat(1,7),4))\n",
    "\n",
    "    diag_weights = ee.List([[1,0,0,0,0,0,0], [1,1,0,0,0,0,0],\\\n",
    "                                [1,1,1,0,0,0,0], [1,1,1,1,0,0,0], \\\n",
    "                                [1,1,1,1,1,0,0], [1,1,1,1,1,1,0], [1,1,1,1,1,1,1]])\n",
    "\n",
    "    rect_kernel = ee.Kernel.fixed(7,7, rect_weights, 3, 3, False)\n",
    "    diag_kernel = ee.Kernel.fixed(7,7, diag_weights, 3, 3, False)\n",
    "\n",
    "    # Create stacks for mean and variance using the original kernels. Mask with relevant direction.\n",
    "    dir_mean = img.reduceNeighborhood(ee.Reducer.mean(), rect_kernel).updateMask(directions.eq(1))\n",
    "    dir_var = img.reduceNeighborhood(ee.Reducer.variance(), rect_kernel).updateMask(directions.eq(1))\n",
    "\n",
    "    dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(), diag_kernel).updateMask(directions.eq(2)))\n",
    "    dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(), diag_kernel).updateMask(directions.eq(2)))\n",
    "\n",
    "    # and add the bands for rotated kernels\n",
    "    #for  (var i=1; i<4; i++):\n",
    "    for i in range(1, 4):\n",
    "        dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(), rect_kernel.rotate(i)) \\\n",
    "                                        .updateMask(directions.eq(2*i+1)))\n",
    "        dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(), rect_kernel.rotate(i)) \\\n",
    "                                        .updateMask(directions.eq(2*i+1)))\n",
    "        dir_mean = dir_mean.addBands(img.reduceNeighborhood(ee.Reducer.mean(), diag_kernel.rotate(i)) \\\n",
    "                                        .updateMask(directions.eq(2*i+2)))\n",
    "        dir_var = dir_var.addBands(img.reduceNeighborhood(ee.Reducer.variance(), diag_kernel.rotate(i)) \\\n",
    "                                        .updateMask(directions.eq(2*i+2)))  \n",
    "\n",
    "    # \"collapse\" the stack into a single band image (due to masking, each pixel has just one value in it's directional band, and is otherwise masked)\n",
    "    dir_mean = dir_mean.reduce(ee.Reducer.sum())\n",
    "    dir_var = dir_var.reduce(ee.Reducer.sum())\n",
    "\n",
    "    # A finally generate the filtered value\n",
    "    varX = dir_var.subtract(dir_mean.multiply(dir_mean).multiply(sigmaV)).divide(sigmaV.add(1.0))\n",
    "\n",
    "    b = varX.divide(dir_var)\n",
    "\n",
    "    result = dir_mean.add(b.multiply(img.subtract(dir_mean)))\n",
    "    \n",
    "    return(result.arrayFlatten([['sum']]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get before-flood and after-flood Refined Lee filtered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_rLee = ee.Image(toDB(RefinedLee(toNatural(before))))\n",
    "after_rLee = ee.Image(toDB(RefinedLee(toNatural(after))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the flood extent. Create a flood extent mask using a threshold value of 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_rLee = after_rLee.divide(before_rLee)\n",
    "\n",
    "DIFF_UPPER_THRESHOLD = 1.25\n",
    "\n",
    "# Identify pixels above the threshold (i.e flood pixels).\n",
    "# Set all other pixels to 0\n",
    "floodMask = difference_rLee.gt(DIFF_UPPER_THRESHOLD).rename('water') \n",
    "\n",
    "# Keep only the flood pixels. Remove all pixels equal to 0\n",
    "floodedAreas = floodMask.selfMask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include JRC layer on surface water seasonality and occurrence to mask flood pixels from\n",
    "areas of \"permanent\" water, i.e., where there is water > 10 months of the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "jrcGSW = ee.Image(\"JRC/GSW1_2/GlobalSurfaceWater\")\n",
    "waterBodies = jrcGSW.select('occurrence').clip(floodedDistricts)\n",
    "vis_waterBodies = {min:0, max:100, \"palette\": '#0D0887'}\n",
    "          \n",
    "Map.addLayer(**{\n",
    "    # mask waterBodies so as to not detect flood in the waterBodies.\n",
    "    # .divide(100) causes the opacity/transparency of the pixels to\n",
    "    # be set based on the waterBodies occurrence value.\n",
    "    \n",
    "    'ee_object': waterBodies.updateMask(waterBodies.divide(100)),\\\n",
    "    'name': \"Permanent water bodies (BLUE)\", \\\n",
    "    'vis_params': vis_waterBodies    \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a mask = 1 if water > 10 months of the year, i.e permanent water pixels\n",
    "\n",
    "Non-permanent water (flood) pixels = 0\n",
    "\n",
    "Remove flood pixels\n",
    "\n",
    "Identify flooded areas that are a minimum 0.25 ha (>= 3 pixels)\n",
    "\n",
    "connectedPixelCount() to get a contiguous area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonality = jrcGSW.select('seasonality')        \n",
    "\n",
    "permWater = seasonality.gte(10).selfMask()\n",
    "  \n",
    "# In the floodedAreas layer, assign all permanent water pixels = 0\n",
    "permWater_removed = floodedAreas.where(permWater,0)\n",
    "  \n",
    "# Remove all the permanent water present in the flooded layer.\n",
    "# floodedAreas layer has only flood pixels\n",
    "onlyFlooded = floodedAreas.updateMask(permWater_removed).selfMask()\n",
    " \n",
    "# Set minimum flood area in pixels = 3, approximately 0.25 ha\n",
    "minFloodPixels = ee.Number(3)\n",
    "  \n",
    "# Scale the results to display on the map. \n",
    "# Reprojecting with a specified scale ensures that the pixel area \n",
    "# does not change with zoom.\n",
    "prj = jrcGSW.projection()\n",
    "scale = prj.nominalScale()\n",
    "contFloodArea = onlyFlooded.connectedPixelCount(25) \\\n",
    "                      .reproject(prj.atScale(scale))\n",
    "                      \n",
    "# Apply the minimum area requirement.\n",
    "minFloodArea = contFloodArea.gte(minFloodPixels).selfMask() \\\n",
    "                    .reproject(prj.atScale(scale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask out areas with more than 5 percent slope using the DEM HydroSHEDS (computing gradients requires a fixed projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "demHydroSHEDS = ee.Image(\"WWF/HydroSHEDS/03VFDEM\")\n",
    "terrain = ee.Algorithms.Terrain(demHydroSHEDS)\n",
    "slope = terrain.select('slope')\n",
    "finalFloodedArea = minFloodArea.updateMask(slope.lt(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import as an Asset - imp_finalFloodedArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_finalFloodedArea = ee.Image(\"users/namratas/FinalFloodedArea\")\n",
    "\n",
    "# Display the flooded areas\n",
    "Map.addLayer(imp_finalFloodedArea.clip(floodedDistricts), {'palette':\"red\", 'opacity': 0.99}, 'Flooded areas (RED)', 1);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the total flooded area (ha)\n",
    "\n",
    "Use pixelArea() to get the value of each pixel in square metres, and sum over the result for a measure of area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "floodedArea = imp_finalFloodedArea.multiply(ee.Image.pixelArea())\n",
    "\n",
    "floodedAreaSize = floodedArea.reduceRegion( **{\n",
    "      'reducer': ee.Reducer.sum(),\n",
    "      'geometry': floodedDistricts.geometry(),\n",
    "      'scale': 30, \n",
    "      'maxPixels': 1e13\n",
    "})\n",
    "\n",
    "# Convert the floodedAreaSize to hectares (area calculations are originally given in meters)\n",
    "# divide by 10,000 to convert to hectare\n",
    "floodedAreaSize = floodedAreaSize.getNumber('water') \\\n",
    "                        .divide(10000) \\\n",
    "                        .round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the area (ha) of flooded agricultural land \n",
    "\n",
    "Identify affected areas that are a minimum 0.5 ha (6 pixels)\n",
    "\n",
    "connectedPixelCount() to get a contiguous area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_gfsad30_Cropland = ee.Image(\"users/namratas/gfsad30_Cropland_Dataset\") \n",
    "gfsad30 = imp_gfsad30_Cropland.clip(floodedDistricts)\n",
    "\n",
    "# Create a raster showing affected agricultural area in the flood layer\n",
    "onlyFloodedAgri = imp_finalFloodedArea.updateMask(gfsad30).selfMask()\n",
    "\n",
    "Map.addLayer(onlyFloodedAgri.select('water'), {'palette': '#2B5329'}, 'Affected Agricultural Land (GREEN)',1)\n",
    "\n",
    "prj = gfsad30.projection()\n",
    "scale = prj.nominalScale()\n",
    "  \n",
    "# Use connectedPixelCount() to get a contiguous area\n",
    "contFloodedAgriArea = onlyFloodedAgri.connectedPixelCount(25) \\\n",
    "                      .reproject(prj.atScale(scale))\n",
    "                      \n",
    "# Set minimum agricultural area = 6 pixels, i.e approximately 0.5 ha\n",
    "minAgriPixels = ee.Number(6)\n",
    "  \n",
    "floodedAgriArea = contFloodedAgriArea.gte(minAgriPixels).selfMask() \\\n",
    "                    .reproject(prj.atScale(scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "affectedAgriArea = onlyFloodedAgri.multiply(ee.Image.pixelArea())\n",
    "  \n",
    "totalAffectedAgriLand = affectedAgriArea.reduceRegion( **{\n",
    "      'reducer': ee.Reducer.sum(),\n",
    "      'geometry': floodedDistricts.geometry(),\n",
    "      'scale': 30, \n",
    "      'maxPixels': 1e13\n",
    "})\n",
    "  \n",
    "# Convert the totalAffectedAgriLand to hectares (area calculations are originally given in meters)\n",
    "# divide by 10,000 to convert to hectare\n",
    "flooded_agriArea_hectares = ee.Number(totalAffectedAgriLand.get('water')) \\\n",
    "                                  .divide(10000) \\\n",
    "                                  .round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the population in the flooded areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popDataset = ee.ImageCollection(\"WorldPop/POP\") \n",
    "  \n",
    "punjabPop  = popDataset \\\n",
    "             .filter(ee.Filter.equals('UNadj', 'no')) \\\n",
    "             .filter(ee.Filter.equals('year', 2015)) \\\n",
    "             .mosaic() \\\n",
    "             .clip(floodedDistricts)\n",
    "\n",
    "# Create a raster showing affected population using the flood layer\n",
    "affectedPopMask = punjabPop.updateMask(finalFloodedArea).selfMask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import as an Asset - imp_affectedPop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_affectedPop = ee.Image(\"users/namratas/affectedPunjabPopulation\") \n",
    "\n",
    "# calculate stats\n",
    "affectedPop = imp_affectedPop.reduceRegion( **{\n",
    "    'reducer': ee.Reducer.sum(),\n",
    "    'geometry': floodedDistricts,\n",
    "    'scale': 100,\n",
    "    'maxPixels': 1e15\n",
    "  })\n",
    "  \n",
    "totalAffectedPop = ee.Number(affectedPop.get('population')).toInt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation with geemap, ipyleaflet and ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up all the necessary widgets\n",
    "layout = widgets.Layout(display='flex',\\\n",
    "                            flex_flow='column',\\\n",
    "                            align_items='stretch',\\\n",
    "                            border='solid'\n",
    "                            )\n",
    "\n",
    "style = {'description_width': 'initial'}\n",
    "\n",
    "floodedAreaHTML = widgets.HTML(\n",
    "    value = f\"<b><font color='bf0f19'>{str(floodedAreaSize.getInfo())}</b>\",\n",
    "    placeholder='',\n",
    "    description= '<b>Flooded Area (in ha) - </b>',\n",
    "    style = style\n",
    ")\n",
    "\n",
    "floodedAgriAreaHTML = widgets.HTML(\n",
    "    value= f\"<b><font color='bf0f19'>{str(flooded_agriArea_hectares.getInfo())}</b>\", \n",
    "    placeholder=' ',\n",
    "    description='<b>Flooded Agricultural Area (in ha) - </b>',\n",
    "    style = style,\n",
    ")\n",
    "\n",
    "affectedPopHTML = widgets.HTML(\n",
    "    value= f\"<b><font color='bf0f19'>{str(totalAffectedPop.getInfo())}</b>\",\n",
    "    placeholder=' ',\n",
    "    description='<b>Affected population - </b>',\n",
    "    style = style,\n",
    ")\n",
    "\n",
    "credits = widgets.HTML(\n",
    "    value='<p style=\"font-size:90%;color:grey\"><b>Credits: </b>Ujaval Gandhi, Founder<a href=\"https://spatialthoughts.com/\"> Spatial Thoughts</a></p>',\n",
    "    placeholder='',\n",
    "    descripition='Credits:'\n",
    ")\n",
    "\n",
    "zoom_slider = widgets.IntSlider(\n",
    "    description='Zoom level:', \n",
    "    min=0, \n",
    "    max=15, \n",
    "    value=8\n",
    ")\n",
    "\n",
    "jslink((zoom_slider, 'value'), (Map, 'zoom'))\n",
    "\n",
    "box = widgets.VBox([floodedAreaHTML, floodedAgriAreaHTML, affectedPopHTML], layout=layout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the widgets to the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704ce82cc1cc4bc88be825ad9635cf75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[30.946658235946547, 75.4731802404629], controls=(WidgetControl(options=['position'], position='botâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = WidgetControl(widget=box, position='topleft')\n",
    "ujaval = WidgetControl(widget=credits, position='bottomleft')\n",
    "zoom = WidgetControl(widget=zoom_slider, position='topright')\n",
    "layers_control = LayersControl(position='topright')\n",
    "\n",
    "legend_dict = {\n",
    "    'flooded areas': 'EB0000',\n",
    "    'affected agricultural area': '2B5329',\n",
    "    'permanent water bodies': '0D0887'\n",
    "}\n",
    "\n",
    "Map.clear_controls()\n",
    "\n",
    "Map.add_legend(legend_title = 'Legend',legend_dict = legend_dict)\n",
    "Map.add_control(results)\n",
    "Map.add_control(ujaval)\n",
    "Map.add_control(zoom)\n",
    "\n",
    "Map.add_control(FullScreenControl())\n",
    "Map.add_control(layers_control)\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Table of Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
